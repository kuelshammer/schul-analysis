# Statistik mit SymPy - Analyse der statistischen Verteilungsfunktionalit√§t

## üìä √úberblick

SymPy bietet umfangreiche Funktionalit√§t f√ºr symbolische Statistik und Wahrscheinlichkeitsrechnung. Dieses Dokument analysiert die Implementierung und Verwendung statistischer Verteilungen, insbesondere f√ºr die Binomial- und Normalverteilung, im Kontext des Schul-Analysis Frameworks.

## üîß Grundlagen der Statistik in SymPy

### Import und Grundstruktur

```python
import sympy as sp
from sympy.stats import *

# SymPy's Statistik-Modul bietet symbolische Wahrscheinlichkeitsrechnung
# Alle Verteilungen sind symbolisch exakt - keine numerischen Approximationen
```

### Kernkonzepte

1. **Symbolische Exaktheit**: Alle Berechnungen bleiben symbolisch exakt
2. **Zufallsvariablen**: Werden mit `density()` oder `sample()` definiert
3. **Verteilungsparameter**: K√∂nnen symbolisch oder numerisch sein
4. **Wahrscheinlichkeitsfunktionen**: PDF, CDF, SF, PPF usw.

## üé≤ Binomialverteilung

### Definition und Grundparameter

```python
import sympy as sp
from sympy.stats import Binomial, P, E, variance

# Symbolische Parameter
n, k = sp.symbols('n k', integer=True, positive=True)
p = sp.symbols('p', real=True, positive=True)

# Binomialverteilte Zufallsvariable
X = Binomial('X', n, p)

# Alternativ mit konkreten Werten
Y = Binomial('Y', 10, 0.3)  # 10 Versuche, p=0.3
```

### Wahrscheinlichkeitsfunktionen

#### Wahrscheinlichkeitsfunktion (PMF - Probability Mass Function)

```python
# PMF f√ºr einen bestimmten Wert k
pmf_k = sp.stats.density(X)(k)
print(f"PMF: P(X=k) = {pmf_k}")

# Vereinfachte Form
pmf_simplified = sp.simplify(pmf_k)
# Ergebnis: binomial(n, k) * p^k * (1-p)^(n-k)
```

#### Kumulative Verteilungsfunktion (CDF)

```python
# CDF f√ºr Wert k
cdf_k = sp.stats.cdf(X)(k)
print(f"CDF: P(X‚â§k) = {cdf_k}")

# Berechnet als Summe: Œ£_{i=0}^k binomial(n,i) * p^i * (1-p)^(n-i)
```

#### √úberlebensfunktion (SF - Survival Function)

```python
# SF: P(X > k)
sf_k = 1 - cdf_k
print(f"SF: P(X>k) = {sf_k}")
```

### Momente und Kenngr√∂√üen

```python
# Erwartungswert
erwartung = E(X)
print(f"E[X] = {erwartung}")  # Ergebnis: n*p

# Varianz
var = variance(X)
print(f"Var[X] = {var}")      # Ergebnis: n*p*(1-p)

# Standardabweichung
std = sp.sqrt(var)
print(f"œÉ[X] = {std}")

# Schiefe (Skewness)
skew = sp.stats.skewness(X)
print(f"Schiefe = {skew}")

# Kurtosis
kurt = sp.stats.kurtosis(X)
print(f"Kurtosis = {kurt}")
```

### Konkrete Berechnungen

```python
# Konkrete Binomialverteilung
n_val, p_val = 10, 0.3
X_konkret = Binomial('X_konkret', n_val, p_val)

# Einzelwahrscheinlichkeiten
P_X_3 = P(X_konkret > 3)
print(f"P(X>3) = {P_X_3.evalf()}")

# Erwartungswert
E_X_konkret = E(X_konkret)
print(f"E[X] = {E_X_konkret.evalf()}")

# Varianz
Var_X_konkret = variance(X_konkret)
print(f"Var[X] = {Var_X_konkret.evalf()}")
```

### Bedingte Wahrscheinlichkeiten

```python
# Bedingte Wahrscheinlichkeit P(X‚â§5 | X‚â•2)
bedingte_wahrscheinlichkeit = P(X <= 5, X >= 2)
print(f"P(X‚â§5|X‚â•2) = {bedingte_wahrscheinlichkeit}")
```

## üìà Normalverteilung

### Definition und Grundparameter

```python
import sympy as sp
from sympy.stats import Normal

# Symbolische Parameter
mu, sigma = sp.symbols('Œº œÉ', real=True, positive=True)
x = sp.symbols('x', real=True)

# Normalverteilte Zufallsvariable
Z = Normal('Z', mu, sigma)

# Standardnormalverteilung
Z_std = Normal('Z_std', 0, 1)

# Konkrete Normalverteilung
N_konkret = Normal('N_konkret', 5, 2)  # Œº=5, œÉ=2
```

### Wahrscheinlichkeitsdichtefunktion (PDF)

```python
# PDF der Normalverteilung
pdf = sp.stats.density(Z)(x)
print(f"PDF: f(x) = {pdf}")

# Vereinfachte Form
pdf_simplified = sp.simplify(pdf)
# Ergebnis: sqrt(2)*exp(-(x-Œº)^2/(2*œÉ^2))/(2*sqrt(pi)*œÉ)

# PDF der Standardnormalverteilung
pdf_std = sp.stats.density(Z_std)(x)
print(f"Standardnormal-PDF: œÜ(x) = {pdf_std}")
# Ergebnis: sqrt(2)*exp(-x^2/2)/(2*sqrt(pi))
```

### Kumulative Verteilungsfunktion (CDF)

```python
# CDF der Normalverteilung
cdf = sp.stats.cdf(Z)(x)
print(f"CDF: F(x) = {cdf}")

# CDF der Standardnormalverteilung (Œ¶-Funktion)
cdf_std = sp.stats.cdf(Z_std)(x)
print(f"Œ¶(x) = {cdf_std}")

# Konkrete Werte
P_Z_lt_2 = P(N_konkret < 7)
print(f"P(Z<7) = {P_Z_lt_2.evalf()}")
```

### Quantilfunktion (PPF - Percent Point Function)

```python
# Inverse CDF (Quantilfunktion)
# F√ºr symbolische Berechnungen kann dies komplex sein
# F√ºr konkrete Werte:
from scipy.stats import norm  # Numerische Alternative

# Konkretes Quantil (75%-Quantil)
quantil_75 = sp.stats.quantile(N_konkret)(0.75)
print(f"75%-Quantil: {quantil_75.evalf()}")
```

### Momente und Kenngr√∂√üen

```python
# Erwartungswert
E_Z = E(Z)
print(f"E[Z] = {E_Z}")  # Ergebnis: Œº

# Varianz
Var_Z = variance(Z)
print(f"Var[Z] = {Var_Z}")  # Ergebnis: œÉ^2

# Standardabweichung
Std_Z = sp.sqrt(Var_Z)
print(f"œÉ[Z] = {Std_Z}")  # Ergebnis: œÉ

# Momente h√∂herer Ordnung
moment_3 = E(Z**3)
print(f"E[Z¬≥] = {moment_3}")

moment_4 = E(Z**4)
print(f"E[Z‚Å¥] = {moment_4}")
```

### Spezielle Eigenschaften der Normalverteilung

```python
# Standardisierung: (X-Œº)/œÉ ~ N(0,1)
X_standardisiert = (Z - mu) / sigma
print(f"Standardisiert: {X_standardisiert}")

# Additionsstabilit√§t: X1+X2 ~ N(Œº1+Œº2, œÉ1¬≤+œÉ2¬≤)
X1 = Normal('X1', mu1, sigma1)
X2 = Normal('X2', mu2, sigma2)
X_summe = X1 + X2
print(f"X1+X2 ~ {X_summe}")
```

## üîó Gemeinsame Verteilungen und Abh√§ngigkeiten

### Korrelation und Kovarianz

```python
from sympy.stats import covariance, correlation

# Zwei Zufallsvariablen mit Korrelation œÅ
rho = sp.symbols('œÅ', real=True)
X, Y = sp.symbols('X Y', cls=sp.RandomSymbol)

# Kovarianz
cov_XY = covariance(X, Y)
print(f"Cov(X,Y) = {cov_XY}")

# Korrelationskoeffizient
corr_XY = correlation(X, Y)
print(f"Corr(X,Y) = {corr_XY}")
```

### Gemeinsame Normalverteilung

```python
# Mehrdimensionale Normalverteilung (konzeptionell)
# In SymPy kann man mit gemeinsamen Verteilungen arbeiten
from sympy.stats import MultivariateNormal

# Parameter f√ºr zweidimensionale Normalverteilung
mu1, mu2 = sp.symbols('Œº1 Œº2', real=True)
sigma1, sigma2 = sp.symbols('œÉ1 œÉ2', real=True, positive=True)
rho = sp.symbols('œÅ', real=True)

# Kovarianzmatrix
cov_matrix = sp.Matrix([
    [sigma1**2, rho*sigma1*sigma2],
    [rho*sigma1*sigma2, sigma2**2]
])

# Gemeinsame Normalverteilung
X_joint = MultivariateNormal('X_joint', [mu1, mu2], cov_matrix)
```

## üìê Approximationen und Grenzwerts√§tze

### Normalapproximation der Binomialverteilung

```python
# Binomialverteilung B(n,p) ‚âà N(np, np(1-p)) f√ºr gro√üe n
mu_approx = n * p
sigma_approx = sp.sqrt(n * p * (1 - p))

# Approximierte Normalverteilung
X_approx = Normal('X_approx', mu_approx, sigma_approx)

# Kontinuit√§tskorrektur f√ºr bessere Approximation
# P(X ‚â§ k) ‚âà P(Y ‚â§ k + 0.5) wobei Y ~ N(np, np(1-p))
k_wert = sp.symbols('k', integer=True)
P_binomial_approx = P(X_approx <= k_wert + 0.5)
print(f"Approximierte Wahrscheinlichkeit: {P_binomial_approx}")
```

### Zentraler Grenzwertsatz

```python
# Konzept: Summe von n unabh√§ngigen Zufallsvariablen
# konvergiert gegen Normalverteilung f√ºr n ‚Üí ‚àû

# Beispiel: Summe von Bernoulli-Variablen ‚Üí Binomial ‚Üí Normal
from sympy.stats import Bernoulli

# n unabh√§ngige Bernoulli(p)-Variablen
bernoullis = [Bernoulli(f'B_{i}', p) for i in range(n)]
summe = sum(bernoullis)

# F√ºr gro√üe n: Summe ‚âà N(np, np(1-p))
print(f"Summe ~ {summe} ‚âà N({mu_approx}, {sigma_approx**2})")
```

## üßÆ Konkrete Berechnungen und Beispiele

### Beispiel 1: Binomialverteilung - M√ºnzw√ºrfe

```python
# 10 M√ºnzw√ºrfe, p=0.5 (faire M√ºnze)
n_muenze, p_muenze = 10, sp.Rational(1, 2)
X_muenze = Binomial('X_muenze', n_muenze, p_muenze)

# Wahrscheinlichkeit f√ºr genau 5 K√∂pfe
P_genau_5 = P(X_muenze == 5)
print(f"P(X=5) = {P_genau_5.evalf()}")  # ‚âà 0.246

# Wahrscheinlichkeit f√ºr mindestens 6 K√∂pfe
P_mindestens_6 = P(X_muenze >= 6)
print(f"P(X‚â•6) = {P_mindestens_6.evalf()}")  # ‚âà 0.377

# Erwartungswert und Varianz
print(f"E[X] = {E(X_muenze).evalf()}")  # 5
print(f"Var[X] = {variance(X_muenze).evalf()}")  # 2.5
```

### Beispiel 2: Normalverteilung - IQ-Verteilung

```python
# IQ-Verteilung: Œº=100, œÉ=15
X_iq = Normal('X_iq', 100, 15)

# Wahrscheinlichkeit f√ºr IQ > 130 (hochbegabt)
P_iq_gt_130 = P(X_iq > 130)
print(f"P(IQ>130) = {P_iq_gt_130.evalf()}")  # ‚âà 0.0228

# 95%-Konfidenzintervall
from scipy.stats import norm
quantil_025 = norm.ppf(0.025, 100, 15)
quantil_975 = norm.ppf(0.975, 100, 15)
print(f"95%-KI: [{quantil_025:.1f}, {quantil_975:.1f}]")  # ‚âà [70.6, 129.4]
```

### Beispiel 3: Hypothesentest

```python
# Einstichproben-Gau√ü-Test
# H0: Œº = Œº0 vs. H1: Œº ‚â† Œº0

# Teststatistik
mu0 = sp.symbols('Œº0', real=True)
x_stichprobe = sp.symbols('xÃÑ', real=True)
n_stichprobe = sp.symbols('n', integer=True, positive=True)

# Teststatistik Z = (xÃÑ - Œº0) / (œÉ/‚àön)
teststatistik = (x_stichprobe - mu0) / (sigma / sp.sqrt(n_stichprobe))
print(f"Teststatistik: Z = {teststatistik}")

# Kritischer Wert f√ºr Œ±=0.05 (zweiseitig)
alpha = 0.05
kritischer_wert = sp.stats.quantile(Z_std)(1 - alpha/2)
print(f"Kritischer Wert: z_{1-alpha/2} = {kritischer_wert.evalf()}")
```

## üîç Symbolische vs. Numerische Berechnungen

### Vorteile der symbolischen Berechnung

1. **Exakte Ergebnisse**: Keine Rundungsfehler
2. **Parametrische L√∂sungen**: Formeln mit symbolischen Parametern
3. **Verst√§ndnis**: Mathematische Struktur bleibt sichtbar
4. **Verifizierung**: Numerische Ergebnisse k√∂nnen √ºberpr√ºft werden

### Grenzen der symbolischen Berechnung

1. **Komplexit√§t**: Ausdr√ºcke k√∂nnen sehr komplex werden
2. **Geschwindigkeit**: Numerische Methoden sind oft schneller
3. **Konvergenz**: Manche Integrale haben keine geschlossene Form

### Hybrider Ansatz

```python
# Symbolische Herleitung, numerische Auswertung
# 1. Symbolische Formel herleiten
formel = sp.stats.density(Z)(x)

# 2. F√ºr konkrete Werte numerisch auswerten
werte = [(i, formel.subs({mu: 0, sigma: 1, x: i}).evalf())
         for i in range(-3, 4)]

print("x | f(x)")
print("---------")
for x_val, fx_val in werte:
    print(f"{x_val:2d} | {fx_val:.4f}")
```

## üéØ Schulrelevante Anwendungen

### Abiturrelevante Themen

1. **Binomialverteilung**
   - Bernoulli-Kette
   - Wahrscheinlichkeitsberechnung
   - Erwartungswert und Varianz
   - Approximation durch Normalverteilung

2. **Normalverteilung**
   - Standardnormalverteilung
   - Sigma-Regeln
   - Konfidenzintervalle
   - Hypothesentests

### P√§dagogische Vorteile

1. **Exakte Berechnungen**: Keine "Black Box" numerischer Methoden
2. **Formelverst√§ndnis**: Sch√ºler sehen die mathematische Struktur
3. **Parameterverst√§ndnis**: Auswirkungen von Parameter√§nderungen sichtbar
4. **Vorbereitung auf Studium**: Symbolische Mathematik wie an Universit√§ten

### Unterrichtseinheiten

#### Einheit 1: Diskrete Verteilungen

- Bernoulli-Experimente
- Binomialverteilung
- Wahrscheinlichkeitsfunktion
- Kumulative Verteilung

#### Einheit 2: Stetige Verteilungen

- Normalverteilung als Grenzwert
- Dichtefunktion
- Verteilungsfunktion
- Standardisierung

#### Einheit 3: Sch√§tzverfahren

- Punkt- und Intervallsch√§tzung
- Konfidenzintervalle
- Hypothesentests
- Fehler 1. und 2. Art

## üí° Integration in SchulAnalysis Framework

### Vorgeschlagene Module

```python
# src/schul_analysis/stochastik/__init__.py
from .binomial import Binomialverteilung
from .normal import Normalverteilung
from .verteilungen import Verteilung

# API-Funktionen (Wrapper)
from .api import (
    Binomialverteilung,
    Normalverteilung,
    Wahrscheinlichkeit,
    Erwartungswert,
    Varianz,
    Standardabweichung,
    Quantil,
    ZeichneVerteilung,
)
```

### Beispiel-API f√ºr SchulAnalysis

```python
from schul_analysis.stochastik import *

# Binomialverteilung
B = Binomialverteilung(n=10, p=0.3)
P_B = Wahrscheinlichkeit(B, k=5)
E_B = Erwartungswert(B)

# Normalverteilung
N = Normalverteilung(mu=100, sigma=15)
P_N = Wahrscheinlichkeit(N, x_bereich=(85, 115))
quantile_N = Quantil(N, alpha=0.95)

# Visualisierung
ZeichneVerteilung(B, typ="balken")  # Balkendiagramm
ZeichneVerteilung(N, typ="kurve")  # Dichtekurve
```

### P√§dagogische Methoden

```python
# Schritt-f√ºr-Schritt Erkl√§rungen
B.erkl√§re_wahrscheinlichkeit(k=5)
B.zeige_approximation_durch_normal()
N.zeige_sigma_regeln()
N.erkl√§re_konfidenzintervall()
```

## üîÆ Weiterf√ºhrende Themen

### Andere Verteilungen in SymPy

1. **Poisson-Verteilung**: F√ºr seltene Ereignisse
2. **Exponentialverteilung**: Wartezeiten
3. **Chi-Quadrat-Verteilung**: Varianzanalyse
4. **t-Verteilung**: Kleine Stichproben
5. **F-Verteilung**: Varianzquotienten

### Multivariate Statistik

1. **Mehrdimensionale Normalverteilung**
2. **Korrelationsanalyse**
3. **Regressionsanalyse**
4. **Varianzanalyse (ANOVA)**

### Stochastische Prozesse

1. **Markov-Ketten**
2. **Poisson-Prozesse**
3. **Brown'sche Bewegung**
4. **Zeitreihenanalyse**

## üìö Zusammenfassung

SymPy bietet leistungsf√§hige Werkzeuge f√ºr die symbolische Statistik, die sich hervorragend f√ºr den schulischen Einsatz eignen:

### St√§rken:

- **Exakte Berechnungen** ohne numerische Approximation
- **Symbolische Parameter** f√ºr allgemeine Formeln
- **P√§dagogische Klarheit** durch sichtbare mathematische Struktur
- **Abitur-Relevanz** durch exakte Ergebnisse
- **Integration** mit bestehender symbolischer Mathematik

### Anwendungsm√∂glichkeiten:

- **Unterrichtsvorbereitung** mit exakten Berechnungen
- **Pr√ºfungsbeispiele** mit symbolischen L√∂sungen
- **Selbstlernmaterial** mit interaktiven Beispielen
- **Projektarbeiten** mit statistischer Analyse
- **Br√ºcke zu universit√§rer Mathematik**

Die Integration in SchulAnalysis w√ºrde das Framework zu einem umfassenden SchulMathematik-System erweitern, das die gesamte Oberstufenmathematik abdeckt.

---

_Erstellt f√ºr das Schul-Analysis Framework_
_Stand: Oktober 2025_
